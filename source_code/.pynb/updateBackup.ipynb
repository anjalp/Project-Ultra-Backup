{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import zipfile as zf\n",
    "from cryptography.fernet import Fernet as fn\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables   ::Same as that of the above code\n",
    "ver_control = 0\n",
    "software_name = 0\n",
    "creator = 0\n",
    "section_UB = 0\n",
    "error = 0\n",
    "def versionControl(section = \"Update Backup\", ver=\"v0.0.2\", soft_name=\"Project Ultra Backup\", author=\"Anjal.P\"):\n",
    "    global ver_control, software_name, creator \n",
    "    ver_control = ver\n",
    "    software_name = soft_name\n",
    "    creator = author\n",
    "    section_UB = section\n",
    "    return ver_control, software_name, creator, section_UB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def errorSave(where_to_save, error_report, root_directory):\n",
    "    global error\n",
    "    where_to_save = where_to_save + \"//\"\n",
    "    print(\"look at: \", where_to_save + \"Error Report UB.txt\")\n",
    "    ver_control, software_name, creator, section = versionControl()\n",
    "    date_error = str(time.localtime(time.time()).tm_mday) + \".\" + str(time.localtime(time.time()).tm_mon) + \".\" + str(time.localtime(time.time()).tm_year)\n",
    "    if os.path.exists(where_to_save + \"Error Report UB.txt\")==False:\n",
    "        try:\n",
    "            with open(where_to_save + \"Error Report UB.txt\", 'a') as error_file:\n",
    "                error_file.write(\"--\"*50 + \"\\n\")\n",
    "                error_file.write(\"Errors :\" + \"[\" +str(error) + \"]\" + \"\\n\")\n",
    "                error_file.write(\"On Running Restore: \" + root_directory + \"\\n\")\n",
    "                error_file.write(\"Created On: \" + date_error + \"\\n\")\n",
    "                error_file.write(\"Report: \\n\")\n",
    "                for eachError in error_report:\n",
    "                    error_file.write(\"     > \" + eachError + \" \" + error_report[eachError])\n",
    "                error_file.write(\"This is an automated report generated by \" + str(software_name) + \" \" + str(ver_control) + \" \" + \"Author: \" + str(creator) + \"\\n\")\n",
    "                error_file.write(\"--\"*50 + \"\\n\")\n",
    "                error_file.close()\n",
    "        except Exception as e:\n",
    "            print(\"Error even creating the error log .txt at: \" + where_to_save + \"Error Report UB.txt\")\n",
    "            print(\"Error Report: \" + str(error_report))\n",
    "            print(\"Error on errorSave: \" + str(e))\n",
    "    else:\n",
    "        try:\n",
    "            with open(where_to_save + \"Error Report UB.txt\", 'a') as error_file:\n",
    "                error_file.write(\"--\"*50 + \"\\n\")\n",
    "                error_file.write(\"Errors :\" + \"[\" +str(error) + \"]\" + \"\\n\")\n",
    "                error_file.write(\"On Running Backup: \" + root_directory + \"\\n\")\n",
    "                error_file.write(\"Created On: \" + date_error + \"\\n\")\n",
    "                error_file.write(\"Report: \\n\")\n",
    "                for eachError in error_report:\n",
    "                    error_file.write(\"     > \" + eachError + \" \" + error_report[eachError])\n",
    "                error_file.write(\"This is an automated report generated by \" + str(software_name) + \" \" + str(ver_control) + \" \" + \"Author: \" + str(creator) + \"\\n\")\n",
    "                error_file.write(\"--\"*50 + \"\\n\")\n",
    "                error_file.close()\n",
    "        except:\n",
    "            print(\"Error even creating the error log .txt at: \" + where_to_save + \"Error Report UB.txt\")\n",
    "            print(\"Error Report: \" + str(error_report))\n",
    "            print(\"Error on errorSave: \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scanHistory(where_to_backup, ubmap_folder, working_dir): #see weather the where_to_backup has any .val file signif. prev. backup\n",
    "    backup_history = {}   #stores the info on date of backup with keys: 0, 1, e.t.c\n",
    "    backup_data = {}   #stores data on the backup folder and its corresponding .val file\n",
    "    ubmap = []   #stores all the ubmap of each backup folder, from comparison from the .val and .ubmap files.\n",
    "    history_count = 0\n",
    "    data_count = 0\n",
    "    backup_base = {}   #this is the place where the {folder:{\"UB_h\":{},\".val\":{}, \".ubmap\":{}}}\n",
    "    isUBPresent = 0\n",
    "    global error\n",
    "    error_report= {}\n",
    "    for folder, subfolder, files in os.walk(where_to_backup):   #scanning the backed up folder and saving the data.\n",
    "        if os.path.basename(folder)[:3]==\"UB_\":\n",
    "            backup_history[history_count] = folder\n",
    "            history_count += 1\n",
    "        for each_file in files:\n",
    "            if each_file[:3]==\"UB_\" and each_file[-4:]==\".val\":\n",
    "                if os.path.basename(folder) not in backup_data.keys():\n",
    "                    backup_data[os.path.basename(folder)] = []\n",
    "                    backup_data[os.path.basename(folder)].append(folder.replace(\"\\\\\", \"//\") + \"//\" + each_file)   #replace here to change \\ to // as \\ creates problem\n",
    "                else:\n",
    "                    backup_data[os.path.basename(folder)].append(folder + \"//\" + each_file)\n",
    "    for ubfiles in os.listdir(ubmap_folder):          #taking care of the ub list session\n",
    "        if ubfiles[-6:]==\".UBmap\" and ubfiles[:3]==\"UB_\":\n",
    "            ubmap.append(ubfiles)\n",
    "    for data in backup_data:\n",
    "        backup_base[data] = {\"UB_h\":[], \".val\":[], \".UBmap\":[]}\n",
    "        for history in backup_history:\n",
    "            if data in os.listdir(backup_history[history]):\n",
    "                if \"oldBackups\" not in backup_history[history]:    #avoid the oldBackups folder as this may mess with the results.\n",
    "                    backup_base[data][\"UB_h\"].append(backup_history[history])\n",
    "        for vsl_files in backup_data[data]:\n",
    "            backup_base[data][\".val\"].append(vsl_files)\n",
    "            for ub_find in ubmap:\n",
    "                if os.path.basename(vsl_files)[:12]==ub_find[:12]:\n",
    "                    backup_base[data][\".UBmap\"].append(ubmap_folder + ub_find)\n",
    "    for mainFolder in backup_base:    #handling if a UBmap is missing.\n",
    "        if len(backup_base[mainFolder][\".UBmap\"])!=len(backup_base[mainFolder][\".val\"]):\n",
    "            error += 1\n",
    "            error_report[\"ubmap missing: \"] = \"It seems that some UBmap files are missing from the ubmap directory.\"\n",
    "            error_report[\"Missing files: \"] = \".val files: \" + str(backup_base[mainFolder][\".val\"]) + \" .ubmap files: \" + str(backup_base[mainFolder][\".UBmap\"])\n",
    "            error_report[\"Plan of action: \"] = \"Proceed with the best option of backup all files for better recovery.\"\n",
    "            errorSave(working_dir, error_report, ubmap_folder)\n",
    "    return backup_base   #return the {folder:{\"UB_h\":[],\".val\":[], \".UBmap\":[]}}\n",
    "#this backup_base is the main dict-list where it get passed to the nect function which opens the root_directorty  nad \n",
    "#compars the files in the root_directory to ubmap if the match is found then the files are not written , moves to next\n",
    "#and so on it continues and at times it amy find new data or modified data which may be required to backup\n",
    "#in that case it remove old eub or sub files and copies the new files to the new history foler with data name\n",
    "#not only this it also modidies the ubmap i.e. it deletes the enteries which has been remove and saves the \n",
    "#old ubmap as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directoryScan(root_directory):               #Scan the given directory ad reutrns the following variables \n",
    "    root_folders = {}                  #variable\n",
    "    folder_no = 0\n",
    "    root_files = {}\n",
    "    file_no = 0\n",
    "    root_size = 0 # in bytes.  \n",
    "    files_properties = {}\n",
    "    if os.path.isdir(root_directory)==False:     #define error in passes root_directory variable\n",
    "        print(\"No such Directory exist.....\")\n",
    "    else:\n",
    "        os.chdir(root_directory)\n",
    "        for each_obj in os.listdir(root_directory):\n",
    "            if os.path.isfile(each_obj)==True:    #if it is a file then do the below code\n",
    "                root_files[file_no] = each_obj\n",
    "                files_properties[file_no] = list(os.stat(each_obj))[6:]   #only contain 4 values size\n",
    "                file_no = file_no + 1\n",
    "            elif os.path.isdir(each_obj)==True:\n",
    "                root_folders[folder_no] = each_obj                  #or if it is a folder :::\n",
    "                folder_no += 1\n",
    "    return root_folders, root_files, files_properties\n",
    "\n",
    "#same function directoly from the createNewBackup code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepToScan(root_directory):\n",
    "    ver_control, software_name, creator, section = versionControl()\n",
    "    folder_det = {}                                         #dict, where the map of the root folder goes.\n",
    "    global error\n",
    "    error_report = {}\n",
    "    basefolder = os.path.basename(root_directory)             #select the base file\n",
    "    split = root_directory.split(\"//\")                       #seperate the selected directory w.r.t //\n",
    "    index_basefolder = split.index(basefolder)                  #index the position of the basefile in the seperated list\n",
    "    elim_sec = '//'.join(split[:index_basefolder]) + '//'              #join all the element of list except the basefile, which can be eliminated using \n",
    "    for folder, subfolder, files in os.walk(root_directory): #using index of the file. This gives the file to eliminate from the 'folder'.\n",
    "        if (\"$RECYCLE.BIN\" or \"found.000\" or \"System Volume Information\") not in folder:\n",
    "            os.chdir(root_directory)\n",
    "            mod_folder = (folder.replace(elim_sec, '')).replace(\"\\\\\", \"//\")\n",
    "            folder_det[mod_folder] = {}\n",
    "            try:\n",
    "                folder_det[mod_folder][\"fo_s\"], folder_det[mod_folder][\"fi_s\"], folder_det[mod_folder][\"fi_p\"] = directoryScan(folder.replace(\"\\\\\", \"//\") + \"//\")\n",
    "            except Exception as e:\n",
    "                error += 1\n",
    "                print(\"Error in directoryScan...\")\n",
    "                error_report[\"directoryScan: \"] = \"Error: \" + str(e)\n",
    "                errorSave(working_dir, error_report, root_directory)\n",
    "    return folder_det, basefolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modifyEngine(previous_backups, root_scan, root_basefolder):\n",
    "    global error \n",
    "    error_report = {}\n",
    "    ubstore = {}\n",
    "    ubmap_root_present = {}   #only common files/folder from ubmap > root\n",
    "    root_ubmap_present = {}    #only common files/folder from root > ubmap\n",
    "    ubmap_root_delete = {}     #files present in ubmap but not in root so move the eub/sub to old_backup folder and delete such enteries from ubmap \n",
    "    root_ubmap_add = {}    #files present in root but not in ubmap so create the new backup folder and zip the new files with new ubmap of the created fioes.\n",
    "    files_prop = {}\n",
    "    len_count = 0\n",
    "    len_zip_count = 0\n",
    "    exceptionHandle = 0\n",
    "    root_ubmap_add = copy.deepcopy(root_scan)\n",
    "    root_ubmap_present = copy.deepcopy(root_scan)\n",
    "    for mainFolder in previous_backups:\n",
    "        if root_basefolder==mainFolder:\n",
    "            ubstore = {}\n",
    "            ubmap_root_present[mainFolder] = {}\n",
    "            ubmap_root_delete[mainFolder] = {}\n",
    "            #initialise and read the all ubmap assosiated with data_backup to ub_store\n",
    "            for read_all_UBmap in previous_backups[mainFolder][\".UBmap\"]:\n",
    "                if os.path.lexists(read_all_UBmap)==True:\n",
    "                    try:\n",
    "                        with open(read_all_UBmap, 'r') as ub_read:\n",
    "                            try:\n",
    "                                ubstore[read_all_UBmap] = json.load(ub_read)\n",
    "                                ub_read.close()\n",
    "                            except Exception as e:\n",
    "                                ub_read.close()\n",
    "                                error += 1\n",
    "                                error_report[\"er_loadJSONUBmap_Engine\"] = \"Error in loading the UBmap: \" + read_all_UBmap + \" Error: \" + str(e)\n",
    "                                error_report[\"Plan of action: \"] = \"Procees with the update, while avoiding the UBmap\" \n",
    "                                errorSave(working_dir, error_report, read_all_UBmap)\n",
    "                    except Exception as e:\n",
    "                        error += 1\n",
    "                        error_report[\"er_readUBmap_Engine\"] = \"Error in reading UBmap \" + read_all_UBmap + \" Error: \" + str(e)\n",
    "                        error_report[\"Plan of action: \"] = \"Procees with the update, while avoiding the UBmap\" \n",
    "                        errorSave(working_dir, error_report, read_all_UBmap)\n",
    "            ubmap_root_present[mainFolder] = copy.deepcopy(ubstore)     # reading finished \n",
    "            ubmap_root_delete[mainFolder] = copy.deepcopy(ubstore)\n",
    "            for eachUB in ubstore:\n",
    "                for data_eachUB in ubstore[eachUB]:\n",
    "                    if data_eachUB in root_scan.keys():\n",
    "                        for each_data_folder in ubstore[eachUB][data_eachUB][\"fo_s\"]:\n",
    "                            if ubstore[eachUB][data_eachUB][\"fo_s\"][each_data_folder] in root_scan[data_eachUB][\"fo_s\"].values():\n",
    "                                try:\n",
    "                                    ubmap_root_delete[mainFolder][eachUB][data_eachUB][\"fo_s\"].pop(each_data_folder)\n",
    "                                except:\n",
    "                                    exceptionHandle += 1\n",
    "                            else:\n",
    "                                try:\n",
    "                                    ubmap_root_present[mainFolder][eachUB][data_eachUB][\"fo_s\"].pop(each_data_folder)\n",
    "                                except:\n",
    "                                    exceptionHandle += 1\n",
    "                        for each_data_file in ubstore[eachUB][data_eachUB][\"fi_s\"]:\n",
    "                            if ubstore[eachUB][data_eachUB][\"fi_s\"][each_data_file] in root_scan[data_eachUB][\"fi_s\"].values():\n",
    "                                key_file = list(root_scan[data_eachUB][\"fi_s\"].keys())[list(root_scan[data_eachUB][\"fi_s\"].values()).index(ubstore[eachUB][data_eachUB][\"fi_s\"][each_data_file])]\n",
    "                                if ubstore[eachUB][data_eachUB][\"fi_p\"][each_data_file][0]==root_scan[data_eachUB][\"fi_p\"][key_file][0] and ubstore[eachUB][data_eachUB][\"fi_p\"][each_data_file][2]==root_scan[data_eachUB][\"fi_p\"][key_file][2] and ubstore[eachUB][data_eachUB][\"fi_p\"][each_data_file][3]==root_scan[data_eachUB][\"fi_p\"][key_file][3]:\n",
    "                                    try:\n",
    "                                        ubmap_root_delete[mainFolder][eachUB][data_eachUB][\"fi_s\"].pop(each_data_file)\n",
    "                                        ubmap_root_delete[mainFolder][eachUB][data_eachUB][\"fi_p\"].pop(each_data_file)\n",
    "                                        ubmap_root_delete[mainFolder][eachUB][data_eachUB][\"z_n\"].pop(each_data_file)\n",
    "                                        ubmap_root_delete[mainFolder][eachUB][data_eachUB][\"k\"].pop(each_data_file)\n",
    "                                    except:\n",
    "                                        exceptionHandle += 1\n",
    "                                else:\n",
    "                                    try:\n",
    "                                        ubmap_root_present[mainFolder][eachUB][data_eachUB][\"fi_s\"].pop(each_data_file)\n",
    "                                        ubmap_root_present[mainFolder][eachUB][data_eachUB][\"fi_p\"].pop(each_data_file)\n",
    "                                        ubmap_root_present[mainFolder][eachUB][data_eachUB][\"z_n\"].pop(each_data_file)\n",
    "                                        ubmap_root_present[mainFolder][eachUB][data_eachUB][\"k\"].pop(each_data_file)\n",
    "                                    except:\n",
    "                                        exceptionHandle += 1\n",
    "                            else:\n",
    "                                try:\n",
    "                                    ubmap_root_present[mainFolder][eachUB][data_eachUB][\"fi_s\"].pop(each_data_file)\n",
    "                                    ubmap_root_present[mainFolder][eachUB][data_eachUB][\"fi_p\"].pop(each_data_file)\n",
    "                                    ubmap_root_present[mainFolder][eachUB][data_eachUB][\"z_n\"].pop(each_data_file)\n",
    "                                    ubmap_root_present[mainFolder][eachUB][data_eachUB][\"k\"].pop(each_data_file)\n",
    "                                except:\n",
    "                                    exceptionHandle += 1\n",
    "                    else:\n",
    "                        try:\n",
    "                            ubmap_root_present[mainFolder][eachUB].pop(data_eachUB)\n",
    "                        except:\n",
    "                            exceptionHandle += 1\n",
    "                for data_Root in root_scan:\n",
    "                    if data_Root in ubstore[eachUB]:\n",
    "        #do not remove fo_s from the root_scan, as this is not logical.\n",
    "                        for files_data_root in root_scan[data_Root][\"fi_s\"]:\n",
    "                            if root_scan[data_Root][\"fi_s\"][files_data_root] in ubstore[eachUB][data_Root][\"fi_s\"].values():\n",
    "                                rkey_file = list(ubstore[eachUB][data_Root][\"fi_s\"].keys())[list(ubstore[eachUB][data_Root][\"fi_s\"].values()).index(root_scan[data_Root][\"fi_s\"][files_data_root])]\n",
    "                                if root_scan[data_Root][\"fi_p\"][files_data_root][0]==ubstore[eachUB][data_Root][\"fi_p\"][rkey_file][0] and root_scan[data_Root][\"fi_p\"][files_data_root][2]==ubstore[eachUB][data_Root][\"fi_p\"][rkey_file][2] and root_scan[data_Root][\"fi_p\"][files_data_root][3]==ubstore[eachUB][data_Root][\"fi_p\"][rkey_file][3]:\n",
    "                                    try:\n",
    "                                        root_ubmap_add[data_Root][\"fi_s\"].pop(files_data_root)\n",
    "                                        root_ubmap_add[data_Root][\"fi_p\"].pop(files_data_root)\n",
    "                                    except:\n",
    "                                        exceptionHandle += 1\n",
    "                                else:\n",
    "                                    try:\n",
    "                                        root_ubmap_present[data_Root][\"fi_s\"].pop(files_data_root)\n",
    "                                        root_ubmap_present[data_Root][\"fi_p\"].pop(files_data_root)\n",
    "                                    except:\n",
    "                                        exceptionHandle += 1\n",
    "                            else:\n",
    "                                try:\n",
    "                                    root_ubmap_present[data_Root][\"fi_s\"].pop(files_data_root)\n",
    "                                    root_ubmap_present[data_Root][\"fi_p\"].pop(files_data_root)\n",
    "                                except:\n",
    "                                    exceptionHandle += 1\n",
    "                    else:\n",
    "                        try:\n",
    "                            root_ubmap_present.pop(data_Root)\n",
    "                        except:\n",
    "                            exceptionHandle += 1\n",
    "    return ubmap_root_present, ubmap_root_delete, root_ubmap_present, root_ubmap_add\n",
    "                #for each_root in root_scan:    #checking root > ubmap realtion\n",
    "                 #   if each_root in ubstore[eachUB].keys():       # check if root directory folders is present in ubmap.\n",
    "# do not change any of the thing in this folder.\n",
    "#during looping throw the dict always assign {**} and .copy() as used above                      \n",
    "#ubmap_root_present is a dict, which return the files present in the both .ubmap and the root_scan i.e. files in root directory. this dict do not contain the files which is present in .ubmap but not in root directory.\n",
    "#ubmap_root_delete : contains the files present in the .ubmap and not in root directory. useful in deleting the corresponding .eub or .sub files.\n",
    "#root_ubmap_add : contains files present in root and not in the .ubmap : this is the list with reference to which new backup is created\n",
    "#root_ubmap_present: which contain the files present in the root and the .ubmap : helps to verify the final output .eub files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipEncryptFiles(fil_dict, dir_loc, nu_ub_files, where_to_B, working_dir):    #Convert the given folder file to a zip and then encrypt the same\n",
    "    limit_zip = 300*1024*1024   #In bytes\n",
    "    size_to = 200*1024*1024   #In bytes\n",
    "    symbol_list = \"~!`@#$%^&()_-+={[}];',\"\n",
    "    zip_name = {}\n",
    "    key = {}                                  #the stuff where zip file get stored\n",
    "    error = 0\n",
    "    error_report = {}\n",
    "    if len(fil_dict)!=0:                                         #creating the files to zip \n",
    "        for files in fil_dict:\n",
    "            if len(fil_dict[files])!=0:\n",
    "                os.chdir(dir_loc)                                     #changing the directory to the fodler in deal.\n",
    "                error_report[files] = {}\n",
    "                rand_range = random.randrange(8, 24)\n",
    "                rand_name = ''.join(random.choices(string.ascii_letters + string.digits + symbol_list, k=rand_range))\n",
    "                fi_name = rand_name + \".zip\"\n",
    "                try: \n",
    "                    rar_file = zf.ZipFile(working_dir + fi_name, 'w')\n",
    "                    try:\n",
    "                        rar_file.write(fil_dict[files], compress_type=zf.ZIP_DEFLATED)\n",
    "                        rar_file.close()\n",
    "                    except Exception as e:\n",
    "                        rar_file.close()\n",
    "                        error += 1\n",
    "                        error_report[\"er_writing_zip\"] = fil_dict[files] + \" Error: \" + str(e)\n",
    "                        error_report[\"Plan of action\"] = \"Proceed with the next file...\"\n",
    "                        errorSave(working_dir, error_report, working_dir)\n",
    "                except Exception as e:\n",
    "                    error += 1\n",
    "                    error_report[\"er_create_zip\"] = working_dir + fi_name + \" Error: \" + str(e)\n",
    "                    error_report[\"Plan of action\"] = \"Proceed with the next file...\"\n",
    "                    errorSave(working_dir, error_report, working_dir)\n",
    "                key[files] = (fn.generate_key()).decode()   #as saving json do not read binary\n",
    "                enc_key = fn(key[files].encode())\n",
    "                os.chdir(working_dir)                           #encrypting the zip and writting to output directory(harddrive)\n",
    "                if os.stat(fi_name).st_size>=limit_zip:                                    #if split needed\n",
    "                    zip_name[files] = {}\n",
    "                    num_split = os.stat(fi_name).st_size//size_to + 1 \n",
    "                    try: \n",
    "                        with open (fi_name, 'rb') as split:\n",
    "                            for volume in range(1, num_split + 1, 1):\n",
    "                                rand_range = random.randrange(8, 24)\n",
    "                                rand_name = ''.join(random.choices(string.ascii_letters + string.digits + symbol_list, k=rand_range))\n",
    "                                split_name = where_to_B + \"//\" + rand_name + \".\"\n",
    "                                zip_name[files][volume] = rand_name \n",
    "                                encr_spl_file = enc_key.encrypt(split.read(size_to))\n",
    "                                try:\n",
    "                                    with open (split_name + \"sUB\", 'wb') as writ_spl:\n",
    "                                        try:\n",
    "                                            writ_spl.write(encr_spl_file)\n",
    "                                            writ_spl.close()\n",
    "                                            nu_ub_files = nu_ub_files + 1  \n",
    "                                        except Exception as e:\n",
    "                                            writ_spl.close()\n",
    "                                            error += 1\n",
    "                                            error_report[\"er_write_sUB file\"] = split_name + \"sUB\" + \" Error: \" + str(e)\n",
    "                                            error_report[\"Plan of action: \"] = \"Proceed with next file to zip and encrypt\"\n",
    "                                            errorSave(working_dir, error_report, split_name)\n",
    "                                except Exception as e:\n",
    "                                    error += 1\n",
    "                                    error_report[\"er_create_sUB file\"] = split_name + \"sUB\" + \" Error: \" + str(e)\n",
    "                                    error_report[\"Plan of action: \"] = \"Proceed with next file to zip and encrypt\"\n",
    "                                    errorSave(working_dir, error_report, split_name)\n",
    "                        split.close()\n",
    "                    except Exception as e:\n",
    "                        error += 1\n",
    "                        error_report[\"er_open_zip to encrypt\"] = working_dir + \"//\" + fi_name + \" Error: \" + str(e)\n",
    "                        error_report[\"Plan of action: \"] = \"Proceed with next file to zip and encrypt\"\n",
    "                        errorSave(working_dir, error_report, working_dir)\n",
    "                    try:\n",
    "                        os.remove(fi_name)                                                     #delete the zip file \n",
    "                    except Exception as e:\n",
    "                        error += 1\n",
    "                        error_report[\"er_deleting_zip\"] = working_dir + fi_name + \"Error: \" + str(e)\n",
    "                        errorSave(working_dir, error_report, working_dir)\n",
    "                else:                                                                  #no split needed\n",
    "                    zip_name[files] = fi_name[:-4]\n",
    "                    try: \n",
    "                        with open (fi_name, 'rb') as no_split:\n",
    "                            no_split_name = where_to_B + \"//\" + fi_name[:-4] + \".\"\n",
    "                            encr_spl_file = enc_key.encrypt(no_split.read())\n",
    "                            try:\n",
    "                                with open (no_split_name + \"eUB\", 'wb') as writ_spl:\n",
    "                                    try: \n",
    "                                        writ_spl.write(encr_spl_file)\n",
    "                                        writ_spl.close()\n",
    "                                        nu_ub_files = nu_ub_files + 1  \n",
    "                                    except Exception as e:\n",
    "                                        writ_spl.close()\n",
    "                                        error += 1\n",
    "                                        error_report[\"er_write_eUB file\"] = no_split_name + \"eUB\" + \" Error: \" + str(e)\n",
    "                                        error_report[\"Plan of action: \"] = \"Proceed with next file to zip and encrypt\"\n",
    "                                        errorSave(working_dir, error_report, no_split_name)\n",
    "                            except Exception as e:\n",
    "                                error += 1\n",
    "                                error_report[\"er_create_eUB file\"] = no_split_name + \"eUB\" + \" Error: \" + str(e)\n",
    "                                error_report[\"Plan of action: \"] = \"Proceed with next file to zip and encrypt\"\n",
    "                                errorSave(working_dir, error_report, no_split_name) \n",
    "                        no_split.close()\n",
    "                    except Exception as e:\n",
    "                        error += 1\n",
    "                        error_report[\"er_open_zip to encrypt\"] = working_dir + \"//\" + fi_name + \" Error: \" + str(e)\n",
    "                        error_report[\"Plan of action: \"] = \"Proceed with next file to zip and encrypt\"\n",
    "                        errorSave(working_dir, error_report, working_dir)\n",
    "                    try:\n",
    "                        os.remove(fi_name)\n",
    "                    except Exception as e:\n",
    "                        error += 1\n",
    "                        error_report[\"er_deleting_zip\"] = working_dir + fi_name + \"Error: \" + str(e)\n",
    "                        errorSave(working_dir, error_report, working_dir)\n",
    "    return zip_name, key, nu_ub_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filesBackup(dict_scan, root_directory, directory_to_backup, working_dir, ubmap_dir):\n",
    "    ver_control, software_name, creator, section = versionControl()\n",
    "    folder_det = dict_scan                                         #dict, where the map of the root folder goes.\n",
    "    max_files = 100\n",
    "    nu_ub_files = 0\n",
    "    global error\n",
    "    error_report = {}\n",
    "    basefolder = os.path.basename(root_directory)                #select the base file\n",
    "    split = root_directory.split(\"//\")                       #seperate the selected directory w.r.t //\n",
    "    index_basefolder = split.index(basefolder)                  #index the position of the basefile in the seperated list\n",
    "    elim_sec = '//'.join(split[:index_basefolder]) + '//'              #join all the element of list except the basefile, which can be eliminated using \n",
    "    ubname = str(time.localtime(time.time()).tm_mday) + \".\" + str(time.localtime(time.time()).tm_mon) + \".\" + str(time.localtime(time.time()).tm_year)\n",
    "    rand_folder = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n",
    "    rand_name = ''.join(random.choices(string.ascii_letters + string.digits, k=8))\n",
    "    backup_to = directory_to_backup + \"//UB_\" + ubname + \"//\" + basefolder + \"//\" + rand_folder\n",
    "    try:\n",
    "        os.makedirs(backup_to)\n",
    "    except Exception as e:\n",
    "        error += 1\n",
    "        error_report[\"er_create_folder: \"] = backup_to\n",
    "        error_report[\"Error: \"] = str(e)\n",
    "        print(\"Try running again...\")\n",
    "        return\n",
    "    for mod_folder in folder_det: #using index of the file. This gives the file to eliminate from the 'folder'.\n",
    "        try:\n",
    "            folder_det[mod_folder][\"z_n\"], folder_det[mod_folder][\"k\"], nu_ub_files = zipEncryptFiles(folder_det[mod_folder][\"fi_s\"], elim_sec + mod_folder + \"//\", nu_ub_files, backup_to + \"//\", working_dir + \"//\")\n",
    "        except Exception as e:\n",
    "            error += 1\n",
    "            error_report[\"er_zipEncryptFiles\"] = \"Error: \" + str(e)\n",
    "            errorSave(working_dir, error_report, root_directory)\n",
    "        if nu_ub_files > max_files:\n",
    "            nu_ub_files = 0\n",
    "            rand_folder = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n",
    "            backup_to = directory_to_backup + \"//UB_\" + ubname + \"//\" + basefolder + \"//\" + rand_folder\n",
    "            try:\n",
    "                os.makedirs(backup_to)\n",
    "            except Exception as e:\n",
    "                error += 1\n",
    "                error_report[\"er_create_folder: \"] = backup_to\n",
    "                error_report[\"Error: \"] = str(e)\n",
    "                print(\"Try running again...\")\n",
    "                return\n",
    "    os.chdir(root_directory)\n",
    "    try: \n",
    "        with open(ubmap_dir + \"//\" + \"UB_\" + rand_name + \"_\" + ubname + \".UBmap\", 'w') as logfile:\n",
    "            try:\n",
    "                json.dump(folder_det, logfile)   #saving as a json file as json only help to read the dict from the file.\n",
    "                logfile.close()\n",
    "            except Exception as e:\n",
    "                logfile.close()\n",
    "                error += 1\n",
    "                error_report[\"er_JSONdump_UBmap\"] = \"Error: \" + str(e)\n",
    "                error_report[\"Plan of action: \"] = \"Delete the created backup at: \" + directory_to_backup + \"//UB_\" + ubname + basefolder + \" and try again\"\n",
    "                errorSave(working_dir, error_report, ubmap_dir + \"//\")\n",
    "                print(\"Delete the created backup at: \" + directory_to_backup + \"//UB_\" + ubname + basefolder + \" and try again\")\n",
    "                return\n",
    "    except Exception as e:\n",
    "        error += 1\n",
    "        error_report[\"er_create_UBmap\"] = \"Error: \" + str(e)\n",
    "        error_report[\"Plan of action: \"] = \"Delete the created backup at: \" + directory_to_backup + \"//UB_\" + ubname + basefolder + \" and try again\"\n",
    "        errorSave(working_dir, error_report, ubmap_dir + \"//\")\n",
    "        print(\"Delete the created backup at: \" + directory_to_backup + \"//UB_\" + ubname + basefolder + \" and try again\")\n",
    "        return\n",
    "    try: \n",
    "        with open(directory_to_backup + \"//UB_\" + ubname + \"//\" + basefolder + \"//\" + \"UB_\" + rand_name + \"_\" + ubname + \".val\", 'w') as verif_file:   #verification file... for unzip\n",
    "            verif_file.write(\"V_File Code: \" + str(rand_name) + \"\\n\")\n",
    "            verif_file.write(\"Created: \" + str(ubname) + \"\\n\")\n",
    "            verif_file.write(\"Backup Of: \" + root_directory + \"\\n\")\n",
    "            verif_file.write(\"Backed Up To: \" + str(directory_to_backup + \"//UB_\" + ubname + \"//\" + basefolder) + \"\\n\")\n",
    "            verif_file.write(\"Mod_list: \" + \"[\" + \"\\\"\" + \"UB_\" + rand_name + \"_\" + ubname + \"\\\"\" + \"]\")\n",
    "            verif_file.write(\"\\n\" + \"--\"*25 + \"\\n\")\n",
    "            verif_file.write(\"This is an automated report generated by \" + str(section) + \" of \" + str(software_name) + \" \" + str(ver_control) + \" \" + \", Author: \" + str(creator))\n",
    "            verif_file.close()\n",
    "    except Exception as e:\n",
    "        error += 1\n",
    "        error_report[\"er_creating_.valfile\"] = \"Error: \" + str(e)\n",
    "        error_report[\"Plan of action: \"] = \"Manualy create a file named: \" + \"UB_\" + rand_name + \"_\" + ubname + \".val\" + \" and leave it as empty and dave at\" + directory_to_backup + \"//UB_\" + ubname + \"//\" + basefolder + \"//\"\n",
    "        errorSave(working_dir, error_report, directory_to_backup + \"//UB_\" + ubname + \"//\" + basefolder + \"//\")\n",
    "        print(\"Error: \" + \"Manualy create a file named: \" + \"UB_\" + rand_name + \"_\" + ubname + \".val\" + \" and leave it as empty and dave at\" + directory_to_backup + \"//UB_\" + ubname + \"//\" + basefolder + \"//\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historyScan(root_folder): # takes the folder as root i.e. : ...UB_6.02.2020//data2\n",
    "    history_scan = {}\n",
    "    for folder, subfolder, files in os.walk(root_folder):\n",
    "        for eachFiles in files:\n",
    "            if os.path.basename(eachFiles)[-4:]==\".eUB\" or os.path.basename(eachFiles)[-4:]==\".sUB\":\n",
    "                history_scan[eachFiles] = folder\n",
    "    return history_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveDotUBFiles(move_dict, backup_directory, previous_map, randVal, working_dir):\n",
    "    ver_control, software_name, creator, section = versionControl()\n",
    "    global error\n",
    "    error_report = {}\n",
    "    files_move = {}\n",
    "    scan_backup = {}\n",
    "    prev_val = {}\n",
    "    date = str(time.localtime(time.time()).tm_mday) + \".\" + str(time.localtime(time.time()).tm_mon) + \".\" + str(time.localtime(time.time()).tm_year)\n",
    "    if os.path.isdir(backup_directory + \"//\" + \"oldBackups\")==False:\n",
    "        try:\n",
    "            os.makedirs(backup_directory + \"//\" + \"oldBackups\")\n",
    "        except Exception as e:\n",
    "            error += 1\n",
    "            error_report[\"er_create_dir_oldBackups\"] = backup_directory + \"//\" + \"oldBackups\"\n",
    "            error_report[\"Error: \"] = str(e)\n",
    "            errorSave(working_dir, error_report, backup_directory)\n",
    "            print(\"Unable to create new direcotry in: \" + backup_directory)\n",
    "            return\n",
    "    for bFolder in move_dict:\n",
    "        for ub_folder in previous_map[bFolder][\"UB_h\"]:       #maing the scan_backup for each history.... to one dict\n",
    "            for ub_val in previous_map[bFolder][\".val\"]:     #making the .val file name to the prev_val so that the .val for the old can be generated\n",
    "                prev_val[os.path.basename(ub_folder)] = ub_val\n",
    "            scan_backup[os.path.basename(ub_folder)] = historyScan(backup_directory + \"//\" + os.path.basename(ub_folder) + \"//\" + bFolder)\n",
    "            if os.path.isdir(backup_directory + \"//\" + \"oldBackups\" + \"//\" + os.path.basename(ub_folder) + \"//\" + bFolder)==False:\n",
    "                try:\n",
    "                    os.makedirs(backup_directory + \"//\" + \"oldBackups\" + \"//\" + os.path.basename(ub_folder) + \"//\" + bFolder)\n",
    "                except Exception as e:\n",
    "                    error += 1\n",
    "                    error_report[\"er_create_oldBackup_mainFolder\"] = backup_directory + \"//\" + \"oldBackups\" + \"//\" + os.path.basename(ub_folder) + \"//\" + bFolder\n",
    "                    error_report[\"Error: \"] = str(e)\n",
    "                    errorSave(working_dir, error_report, backup_directory)\n",
    "                    print(\"Error creating: \" + str(backup_directory + \"//\" + \"oldBackups\" + \"//\" + os.path.basename(ub_folder) + \"//\" + bFolder))\n",
    "                    return\n",
    "        for eachUB in move_dict[bFolder]:             # taking all the files from the move dict.., which has to be moved to one dict\n",
    "            ub_date = \"UB_\" + os.path.basename(eachUB)[:-6].replace(os.path.basename(eachUB)[:-6][:12], '')\n",
    "            files_move[ub_date] = []\n",
    "            for data_each in move_dict[bFolder][eachUB]:\n",
    "                for files in move_dict[bFolder][eachUB][data_each][\"fi_s\"]:\n",
    "                    if type(move_dict[bFolder][eachUB][data_each][\"z_n\"][files])==type({}):\n",
    "                        for each_dict in move_dict[bFolder][eachUB][data_each][\"z_n\"][files].values():\n",
    "                            files_move[ub_date].append(each_dict + \".sUB\")\n",
    "                    else:\n",
    "                        files_move[ub_date].append(move_dict[bFolder][eachUB][data_each][\"z_n\"][files] + \".eUB\")\n",
    "        for each_history in files_move:      #moving the files form the move_dict folder, w.r.t the scan_backup.    \n",
    "            if len(files_move[each_history])!=0:\n",
    "                for files in files_move[each_history]:\n",
    "                    if files in scan_backup[each_history].keys():\n",
    "                        from_move = scan_backup[each_history][files] + \"//\" + files\n",
    "                        to_move = backup_directory + \"//\" + \"oldBackups\" + \"//\" + each_history + \"//\" + bFolder + \"//\" + os.path.basename(scan_backup[each_history][files])\n",
    "                        if os.path.isdir(to_move)==False:\n",
    "                            try:\n",
    "                                os.makedirs(to_move)\n",
    "                            except Exception as e:\n",
    "                                error += 1\n",
    "                                error_report[\"er_create_dir\"] = to_move\n",
    "                                error_report[\"Error: \"] = str(e)\n",
    "                                errorSave(working_dir, error_report, backup_directory)\n",
    "                                return\n",
    "                        try:\n",
    "                            shutil.move(from_move, to_move)\n",
    "                        except Exception as e:\n",
    "                            error += 1\n",
    "                            error_report[\"er_moving_files\"] = from_move + \" to \" + to_move\n",
    "                            error_report[\"Error\"] = str(e)\n",
    "                            error_report[\"Plan of action: \"] = \"Try manually moving the files: from\" + from_move + \" to move to location: \" + to_move\n",
    "                            errorSave(working_dir, error_report, backup_directory)\n",
    "                    try:\n",
    "                        with open(backup_directory + \"//\" + \"oldBackups\" + \"//\" + each_history + \"//\" + bFolder + \"//\" + \"old_\" + randVal + \"_\" + os.path.basename(prev_val[each_history]), 'w') as oldVal:\n",
    "                            oldVal.write(\"V_File Code: \" + os.path.basename(prev_val[each_history])[3:11] + \"\\n\")\n",
    "                            oldVal.write(\"Part: \" + each_history + \" >> \" + bFolder + \" >> \" + \"eUB/sUB Files\" + \"\\n\")\n",
    "                            oldVal.write(\"Created on: \" + each_history[3:] + \"\\n\")\n",
    "                            oldVal.write(\"Modified on: \" + date + \"\\n\")\n",
    "                            oldVal.write(\"Items Moved: \" + \"\\n\" + \"     \")\n",
    "                            oldVal.write(str(files_move[each_history]))\n",
    "                            oldVal.write(\"\\n\" + \"--\"*25 + \"\\n\")\n",
    "                            oldVal.write(\"This is an automated report generated by \" + str(section) + \" of \" + str(software_name) + \" \" + str(ver_control) + \" \" + \", Author: \" + str(creator))\n",
    "                            oldVal.write(\"\\n\\n\\n\")\n",
    "                            oldVal.close()\n",
    "                    except Exception as e:\n",
    "                        error += 1\n",
    "                        error_report[\"er_create_oldbackup_.val file\"] = backup_directory + \"//\" + \"oldBackups\" + \"//\" + each_history + \"//\" + bFolder + \"//\" + \"old_\" + randVal + \"_\" + os.path.basename(prev_val[each_history])\n",
    "                        error_report[\"Error: \"] = str(e)\n",
    "                        error_report[\"Plan of action: \"] = \"Try manually create the file: \" + backup_directory + \"//\" + \"oldBackups\" + \"//\" + each_history + \"//\" + bFolder + \"//\" + \"old_\" + randVal + \"_\" + os.path.basename(prev_val[each_history]) + \" without anything in it,\"\n",
    "                        errorSave(working_dir, error_report, backup_directory)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeUBmap(ubmap_history, ubmap_dir, randUB, working_dir):\n",
    "    global error\n",
    "    error_report = {}\n",
    "    if os.path.isdir(ubmap_dir + \"//\" + \"oldUBmap\")==False:\n",
    "        try:\n",
    "            os.makedirs(ubmap_dir + \"//\" + \"oldUBmap\")\n",
    "        except Exception as e:\n",
    "            error += 1\n",
    "            error_report[\"er_create_oldUBmap folder\"] = ubmap_dir + \"//\" + \"oldUBmap\"\n",
    "            error_report[\"Error: \"] = str(e)\n",
    "            error_report[\"Plan of action : \"] = \"This error will make you to not rollback to previous backups to restore as be careful..\"\n",
    "            errorSave(working_dir, error_report, ubmap_dir)\n",
    "            return\n",
    "    for mainFolder in ubmap_history:\n",
    "        for ub in ubmap_history[mainFolder]:\n",
    "            basenameUB = os.path.basename(ub)\n",
    "            rename_UB = \"old_\" + randUB + \"_\" + basenameUB\n",
    "            try:\n",
    "                shutil.move(ub, ubmap_dir + \"//\" + \"oldUBmap\" + \"//\" + rename_UB)\n",
    "            except Exception as e:\n",
    "                error += 1\n",
    "                error_report[\"er_moving_ubmap file\"] = ub\n",
    "                error_report[\"Error: \"] = str(e)\n",
    "                error_report[\"Plan of action: \"] = \"The previous UBmap files are not moved to oldUBmap folder.\"\n",
    "                errorSave(working_dir, error_report, ub)\n",
    "            try:\n",
    "                with open(ubmap_dir + \"//\" + basenameUB, 'w') as newUBmap:\n",
    "                    try:\n",
    "                        json.dump(ubmap_history[mainFolder][ub], newUBmap)\n",
    "                        newUBmap.close()\n",
    "                    except Exception as e:\n",
    "                        newUBmap.close()\n",
    "                        error += 1\n",
    "                        error_report[\"er_dumpJSON_createNewUBmap\"] = ubmap_dir + \"//\" + basenameUB\n",
    "                        error_report[\"Error: \"] = str(e)\n",
    "                        error_report[\"Plan of action: \"] = \"Try create new backup.\"\n",
    "                        errorSave(working_dir, error_report, ubmap_dir)\n",
    "                        return\n",
    "            except Exception as e:\n",
    "                error += 1\n",
    "                error_report[\"er_create_newUBmap\"] = ubmap_dir + \"//\" + basenameUB\n",
    "                error_report[\"Error: \"] = str(e)\n",
    "                error_report[\"Plan of action: \"] = \"Try create new backup.\"\n",
    "                errorSave(working_dir, error_report, ubmap_dir)\n",
    "                return\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(root_directory, directory_to_backup, working_dir, ubmap_dir):\n",
    "    global error\n",
    "    change_UBmap_history = {}\n",
    "    move_eub_sub = {}\n",
    "    verify = {}\n",
    "    folder_det_new = {}\n",
    "    perform_newBackup = False\n",
    "    perform_modify = False\n",
    "    error_report = {}\n",
    "    try:\n",
    "        dig_previous = scanHistory(directory_to_backup + \"//\", ubmap_dir + \"//\", working_dir)\n",
    "    except Exception as e:\n",
    "        error += 1\n",
    "        error_report[\"scanHistory\"] = \"Error: \" + str(e)\n",
    "        errorSave(working_dir, error_report, root_directory)\n",
    "        print(\"Error, scanHistory: Try the precess again\")\n",
    "        return\n",
    "    try:\n",
    "        root_scan, basefolder = prepToScan(root_directory)   #do not give the end \"//\" as this is not required\n",
    "    except Exception as e:\n",
    "        error += 1\n",
    "        error_report[\"prepToScan\"] = \"Error: \" + str(e)\n",
    "        errorSave(working_dir, error_report, root_directory)\n",
    "        print(\"Error, prepToScan: Try the precess again\")\n",
    "        return\n",
    "    try:\n",
    "        change_UBmap_history, move_eub_sub, verify, new_Backup = modifyEngine(dig_previous, root_scan, basefolder)\n",
    "    except Exception as e:\n",
    "        error += 1\n",
    "        error_report[\"modifyEngine\"] = \"Error: \" + str(e)\n",
    "        errorSave(working_dir, error_report, root_directory)\n",
    "        print(\"Error, modifyEngine: Try the precess again\")\n",
    "        return\n",
    "    for data in new_Backup:    #rule out if there is new backup required required : i.e. if all the files are the same and there is not need of updatre\n",
    "        for each_data in new_Backup[data][\"fi_s\"]:\n",
    "            if len(new_Backup[data][\"fi_s\"][each_data])!=0:\n",
    "                perform_newBackup = True\n",
    "                break\n",
    "    for mainFolder in move_eub_sub:   #looking for the file in the move_eub_sub, if this has no files oto replace then the perform_modify return a False\n",
    "        for ub in move_eub_sub[mainFolder]:\n",
    "            for data in move_eub_sub[mainFolder][ub]:\n",
    "                for files in move_eub_sub[mainFolder][ub][data][\"fi_s\"]:\n",
    "                    if len(move_eub_sub[mainFolder][ub][data][\"fi_s\"][files])!=0:\n",
    "                        perform_modify = True\n",
    "                        break   \n",
    "    if perform_newBackup==True and perform_modify==True:  #perform new backup plus copy the modified files\n",
    "        print(\"Found new files to backup and Updating existing backups.\")\n",
    "        try:\n",
    "            filesBackup(new_Backup, root_directory, directory_to_backup, working_dir, ubmap_dir)\n",
    "        except Exception as e:\n",
    "            error += 1\n",
    "            error_report[\"filesBackup\"] = \"Error: \" + str(e)\n",
    "            errorSave(working_dir, error_report, root_directory)\n",
    "            print(\"Error in filesBackup: Try the precess again\")\n",
    "            return\n",
    "        randUB = ''.join(random.choices(string.ascii_letters + string.digits, k=8))\n",
    "        try:\n",
    "            moveDotUBFiles(move_eub_sub, directory_to_backup + \"//\", dig_previous, randUB, working_dir)\n",
    "        except Exception as e:\n",
    "            error += 1\n",
    "            error_report[\"moveDotUBFiles\"] = \"Error: \" + str(e)\n",
    "            errorSave(working_dir, error_report, root_directory)\n",
    "            print(\"Error in filesBackup: Try the precess again\")\n",
    "            return\n",
    "        try:\n",
    "            changeUBmap(change_UBmap_history, ubmap_dir + \"//\", randUB, working_dir)\n",
    "        except Exception as e:\n",
    "            error += 1\n",
    "            error_report[\"changeUBmap\"] = \"Error: \" + str(e)\n",
    "            errorSave(working_dir, error_report, root_directory)\n",
    "            print(\"Error in changeUBmap: Try the precess again\")\n",
    "            return\n",
    "    elif perform_modify==True:   #No new files found, so only modify the existing one\n",
    "        print(\"Updating existing backups, No new Files to backup.\")\n",
    "        randUB = ''.join(random.choices(string.ascii_letters + string.digits, k=8))\n",
    "        try:\n",
    "            moveDotUBFiles(move_eub_sub, directory_to_backup + \"//\", dig_previous, randUB, working_dir)\n",
    "        except Exception as e:\n",
    "            error += 1\n",
    "            error_report[\"moveDotUBFiles\"] = \"Error: \" + str(e)\n",
    "            errorSave(working_dir, error_report, root_directory)\n",
    "            print(\"Error in filesBackup: Try the precess again\")\n",
    "            return\n",
    "        try:\n",
    "            changeUBmap(change_UBmap_history, ubmap_dir + \"//\", randUB, working_dir)\n",
    "        except Exception as e:\n",
    "            error += 1\n",
    "            error_report[\"changeUBmap\"] = \"Error: \" + str(e)\n",
    "            errorSave(working_dir, error_report, root_directory)\n",
    "            print(\"Error in changeUBmap: Try the precess again\")\n",
    "            return\n",
    "    elif perform_newBackup==True:    #No modification of files found so only backup the mew ones\n",
    "        print(\"Found new Files to backup, No update found.\")\n",
    "        try:\n",
    "            filesBackup(new_Backup, root_directory, directory_to_backup, working_dir, ubmap_dir)\n",
    "        except Exception as e:\n",
    "            error += 1\n",
    "            error_report[\"filesBackup\"] = \"Error: \" + str(e)\n",
    "            errorSave(working_dir, error_report, root_directory)\n",
    "            print(\"Error in filesBackup: Try the precess again\")\n",
    "            return\n",
    "    else:   # no new files or modification, so backup not necessery.\n",
    "        print(\"All files already in backup.\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateBackup(root_directory, directory_to_backup, working_dir, ubmap_dir):\n",
    "    global error\n",
    "    error_report = {}\n",
    "    exception_folder = [\"$RECYCLE.BIN\", \"found.000\", \"System Volume Information\"]\n",
    "    if root_directory.find(\"\\\\\")!=-1:                    #change all the \\ to //\n",
    "        root_directory = root_directory.replace(\"\\\\\", \"//\")\n",
    "    if directory_to_backup.find(\"\\\\\")!=-1:\n",
    "        directory_to_backup = directory_to_backup.replace(\"\\\\\", \"//\")\n",
    "    if working_dir.find(\"\\\\\")!=-1:\n",
    "        working_dir = working_dir.replace(\"\\\\\", \"//\")\n",
    "    if ubmap_dir.find(\"\\\\\")!=-1:\n",
    "        ubmap_dir.replace(\"\\\\\", \"//\")\n",
    "    if os.path.isdir(root_directory)==False:    #check if all the folder exist.\n",
    "        error += 1 \n",
    "        print(\"root directory not found.....\")\n",
    "        error_report[\"Major error: \"] = root_directory + \" Not found\"\n",
    "        errorSave(working_dir, error_report, root_directory)\n",
    "        return\n",
    "    if os.path.isdir(directory_to_backup)==False:\n",
    "        error += 1 \n",
    "        print(\"directory to backup not found.....\")\n",
    "        error_report[\"Major error: \"] = directory_to_backup + \" Not found\"\n",
    "        errorSave(working_dir, error_report, root_directory)\n",
    "        return\n",
    "    if os.path.isdir(working_dir)==False:\n",
    "        error += 1 \n",
    "        print(\"working directory not found.....\")\n",
    "        error_report[\"Major error: \"] = working_dir + \" Not found\"\n",
    "        errorSave(working_dir, error_report, root_directory)\n",
    "        return\n",
    "    if os.path.isdir(ubmap_dir)==False:\n",
    "        error += 1 \n",
    "        print(\"ubmap directory not found.....\")\n",
    "        error_report[\"Major error: \"] = ubmap_dir + \" Not found\"\n",
    "        errorSave(working_dir, error_report, root_directory)\n",
    "        return\n",
    "    split = root_directory.split(\"//\")   # make the code available for the root to be drive. i.e. each folder seperatly.\n",
    "    if len(split)==2 and split[1]=='':   #condition where the root seems to be inside the dirve, so divide the task and \n",
    "        list_folders = os.listdir(root_directory)\n",
    "        for each_root in list_folders:\n",
    "            if each_root not in exception_folder:\n",
    "                if os.path.isdir(root_directory + \"//\" + each_root)==True:\n",
    "                    try:\n",
    "                        main(root_directory + each_root, directory_to_backup, working_dir, ubmap_dir)\n",
    "                    except Exception as e:\n",
    "                        error += 1\n",
    "                        print(\"Error: main function not working...\")\n",
    "                        error_report[each_root] = \"error in main function: \" + str(e)\n",
    "                        errorSave(working_dir, error_report, root_directory + each_root)\n",
    "                        return       \n",
    "    else:\n",
    "        try:\n",
    "            main(root_directory, directory_to_backup, working_dir, ubmap_dir)\n",
    "        except Exception as e:\n",
    "            error += 1\n",
    "            print(\"Error: main function not working.....\")\n",
    "            error_report[root_directory] = \"error in main function: \" + str(e)\n",
    "            errorSave(working_dir, error_report, root_directory)\n",
    "            return\n",
    "    return \"Success\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
