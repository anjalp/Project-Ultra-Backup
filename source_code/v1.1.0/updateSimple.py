import os
import json
import shutil
import copy
import time
import random
import string

import createSimple as cS


ver_control = 0
software_name = 0
creator = 0
def globalVariable(ver="v1.1.0", soft_name="Project Ultra Backup", author="Anjal.P"):
    global ver_control, software_name, creator 
    ver_control = ver
    software_name = soft_name
    creator = author
    return ver_control, software_name, creator


def errorSave(where_to_save, error_report, root_directory):
    global error
    where_to_save = where_to_save + "//"
    print("Error::")
    print("look at: ", where_to_save + "Error Report UB.txt")
    ver_control, software_name, creator = globalVariable()
    date_error = str(time.localtime(time.time()).tm_mday) + "." + str(time.localtime(time.time()).tm_mon) + "." + str(time.localtime(time.time()).tm_year)
    if os.path.exists(where_to_save + "Error Report UB.txt")==False:
        try:
            with open(where_to_save + "Error Report UB.txt", 'a') as error_file:
                error_file.write("--"*50 + "\n")
                error_file.write("On Running Restore: " + root_directory + "\n")
                error_file.write("Created On: " + date_error + "\n")
                error_file.write("Report: \n")
                for eachError in error_report:
                    error_file.write("     > " + eachError + " " + error_report[eachError] + "\n")
                error_file.write("This is an automated report generated by " + str(software_name) + " " + str(ver_control) + " " + "Author: " + str(creator) + "\n")
                error_file.write("--"*50 + "\n")
                error_file.close()
        except Exception as e:
            print("Error even creating the error log .txt at: " + where_to_save + "Error Report UB.txt")
            print("Error Report: " + str(error_report))
            print("Error on errorSave: " + str(e))
    else:
        try:
            with open(where_to_save + "Error Report UB.txt", 'a') as error_file:
                error_file.write("--"*50 + "\n")
                error_file.write("On Running Backup: " + root_directory + "\n")
                error_file.write("Created On: " + date_error + "\n")
                error_file.write("Report: \n")
                for eachError in error_report:
                    error_file.write("     > " + eachError + " " + error_report[eachError] + "\n")
                error_file.write("This is an automated report generated by " + str(software_name) + " " + str(ver_control) + " " + "Author: " + str(creator) + "\n")
                error_file.write("--"*50 + "\n")
                error_file.close()
        except:
            print("Error even creating the error log .txt at: " + where_to_save + "Error Report UB.txt")
            print("Error Report: " + str(error_report))
            print("Error on errorSave: " + str(e))
    return


def directoryScan(root_directory):              
    root_folders = {}               
    folder_no = 0
    root_files = {}
    file_no = 0
    root_size = 0  
    files_properties = {}
    if os.path.isdir(root_directory)==False:     
        print("No such Directory exist.....")
    else:
        os.chdir(root_directory)
        for each_obj in os.listdir(root_directory):
            if os.path.isfile(each_obj)==True:   
                root_files[file_no] = each_obj
                files_properties[file_no] = list(os.stat(each_obj))[6:]   
                file_no = file_no + 1
            elif os.path.isdir(each_obj)==True:
                root_folders[folder_no] = each_obj                 
                folder_no += 1
    return root_folders, root_files, files_properties


def updateEngine(root_directory, backup_folder, folder_scan):
    new_files = {}
    old_files = {}
    errorReport = {}
    ubs_attendence = 0
    date = str(time.localtime(time.time()).tm_mday) + "." + str(time.localtime(time.time()).tm_mon) + "." + str(time.localtime(time.time()).tm_year)
    rand_name = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
    basename = os.path.basename(root_directory)
    if os.path.isdir(backup_folder + basename)==False:
        print("Sorry, there is no previous Backup Record, Creating a New Backup.")
        try:
            cS.createSimpleBackup(root_directory, backup_folder)
        except Exception as e:
            errorReport["er_createSimpleBackup"] = root_directory + " to " + backup_folder
            errorReport["Exception: "] = str(e)
            errorSave(root_directory, errorReport, backup_folder)
        return
    for allFiles in os.listdir(backup_folder + basename):
        if allFiles[:3]=="UB_" and allFiles[-4:]==".UBs":
            ubfileName = allFiles
            ubs_attendence = 1
            try: 
                with open(backup_folder + basename + "//" + allFiles, 'r') as prevUB:
                    prev_data = json.load(prevUB)
                    prevUB.close()
            except Exception as e:
                errorReport["er_open_UBs"] = backup_folder + basename + "//" + allFiles
                errorReport["Error: "] = str(e)
                errorSave(root_directory, errorReport, backup_folder)
            break
    if ubs_attendence==0:
        print("No .UBs found, so Update Cannot Proceed.")
        print("Creating a New Backup: ")
        try:
            cS.createSimpleBackup(root_directory, backup_folder)
        except Exception as e:
            errorReport["er_createSimpleBackup"] = root_directory + " to " + backup_folder
            errorReport["Exception: "] = str(e)
            errorSave(root_directory, errorReport, backup_folder)
        return 
    new_files = copy.deepcopy(folder_scan)
    old_files = copy.deepcopy(prev_data)
    for eachfoldr in folder_scan:  
        if eachfoldr in prev_data.keys():
            for fold in folder_scan[eachfoldr]["fo_s"]:
                if folder_scan[eachfoldr]["fo_s"][fold] in prev_data[eachfoldr]["fo_s"].values():
                    new_files[eachfoldr]["fo_s"].pop(fold)
            for eachFiles in folder_scan[eachfoldr]["fi_s"]:
                if folder_scan[eachfoldr]["fi_s"][eachFiles] in prev_data[eachfoldr]["fi_s"].values():
                    key = list(prev_data[eachfoldr]["fi_s"].keys())[list(prev_data[eachfoldr]["fi_s"].values()).index(folder_scan[eachfoldr]["fi_s"][eachFiles])]
                    if folder_scan[eachfoldr]["fi_p"][eachFiles][0] == prev_data[eachfoldr]["fi_p"][key][0] and folder_scan[eachfoldr]["fi_p"][eachFiles][2] == prev_data[eachfoldr]["fi_p"][key][2] and folder_scan[eachfoldr]["fi_p"][eachFiles][3] == prev_data[eachfoldr]["fi_p"][key][3]:
                        new_files[eachfoldr]["fi_s"].pop(eachFiles)
                        new_files[eachfoldr]["fi_p"].pop(eachFiles)
    to_backup = copy.deepcopy(new_files)
    for each in new_files:   
        if len(new_files[each]["fi_s"])==0 and len(new_files[each]["fo_s"])==0:
            to_backup.pop(each)
    for preveach in prev_data:
        if preveach in folder_scan.keys():
            for foldroot in prev_data[preveach]["fo_s"]:
                if prev_data[preveach]["fo_s"][foldroot] in folder_scan[preveach]["fo_s"].values():
                    old_files[preveach]["fo_s"].pop(foldroot)
            for eachfiles in prev_data[preveach]["fi_s"]:
                if prev_data[preveach]["fi_s"][eachfiles] in folder_scan[preveach]["fi_s"].values():
                    key = list(folder_scan[preveach]["fi_s"].keys())[list(folder_scan[preveach]["fi_s"].values()).index(prev_data[preveach]["fi_s"][eachfiles])]
                    if prev_data[preveach]["fi_p"][eachfiles][0] ==folder_scan[preveach]["fi_p"][key][0] and prev_data[preveach]["fi_p"][eachfiles][2] ==folder_scan[preveach]["fi_p"][key][2] and prev_data[preveach]["fi_p"][eachfiles][3] ==folder_scan[preveach]["fi_p"][key][3]:
                        old_files[preveach]["fi_s"].pop(eachfiles)
                        old_files[preveach]["fi_p"].pop(eachfiles)
    to_archieve = copy.deepcopy(old_files)
    for each in old_files: 
        if len(old_files[each]["fi_s"])==0 and len(old_files[each]["fo_s"])==0:
            to_archieve.pop(each) 
    if len(to_archieve)==0:
        print("No file to Archive")
    else:
        print("Found some files to Archive.")
        if os.path.isdir(backup_folder + "UB_Archive" + "//" + date)==False:
            try:
                os.makedirs(backup_folder + "UB_Archive" + "//" + date)
            except Exception as e:
                errorReport["er_create_UB archieve"] = backup_folder + "UB_Archive" + "//" + date
                errorReport["Error: "] = str(e)
                print("Archive folder cannot be made...")
                errorSave(root_directory, errorReport, backup_folder)
                return
        for archievefolder in to_archieve:
            if os.path.isdir(backup_folder + "UB_Archive" + "//" + date + "//" + archievefolder)==False:
                os.makedirs(backup_folder + "UB_Archive" + "//" + date + "//"  + archievefolder)
            for filesMove in to_archieve[archievefolder]["fi_s"]:
                if os.path.isfile(backup_folder + archievefolder + "//" + to_archieve[archievefolder]["fi_s"][filesMove])==True:
                    try:
                        shutil.move(backup_folder + archievefolder + "//" + to_archieve[archievefolder]["fi_s"][filesMove], backup_folder + "UB_Archive" + "//" + date + "//" + archievefolder + "//")
                    except Exception as e:
                        errorReport["er_moving: "] = backup_folder + archievefolder + "//" + to_archieve[archievefolder]["fi_s"][filesMove] + " to " + backup_folder + "UB_Archive" + "//" + date + "//" + archievefolder + "//"
                        errorReport["Error: "] = str(e)
                        errorSave(root_directory, errorReport, backup_folder)
                    #print(".", end='', flush=True) # old version v1.0.0

                    #UPDATE FOR FEATURE ENHANCEMENT ON v1.1.0
                    #This displays the file that is currently backuped, from the previously used . for each file backuped.
                    print("Archive: " + backup_folder + archievefolder + "//" + to_archieve[archievefolder]["fi_s"][filesMove], flush=True)
        for delFolder in old_files:
            if os.path.isdir(backup_folder + delFolder)==True:
                if delFolder not in folder_scan:
                    try: 
                        shutil.rmtree(backup_folder + delFolder)
                    except Exception as e:
                        errorReport["er_remove directory: "] = backup_folder + delFolder
                        errorReport["Error: "] = str(e)
                        errorSave(root_directory, errorReport, backup_folder)
        try:
            with open(backup_folder + "UB_Archive" + "//" + date + "//"  + basename + "//" + "UB_" + date + ".UBar", 'w') as archUB:
                json.dump(to_archieve, archUB)
                archUB.close()
        except Exception as e:
            errorReport["er_create_UBs"] = backup_folder + "UB_Archive" + "//" + date + "//"  + basename + "//" + "UB_" + date + ".UBar"
            errorReport["Error: "] = str(e)
            errorSave(root_directory, errorReport, backup_folder)
    if len(to_backup)==0:
        print("No new Files to Backup")
    else:
        print("Found Some Files to Backup")
        root_directory = root_directory.replace(basename, '')
        for copyNew in to_backup:
            if os.path.isdir(backup_folder + copyNew + "//")==False:
                try:
                    os.makedirs(backup_folder + copyNew + "//")
                except Exception as e:
                    errorReport["er_create_folder: "] = backup_folder + copyNew + "//"
                    errorReport["Error: "] = str(e)
                    errorSave(root_directory, errorReport, backup_folder)
            for filesCopy in to_backup[copyNew]["fi_s"]:
                try: 
                    shutil.copy(root_directory + "//" + copyNew + "//" + to_backup[copyNew]["fi_s"][filesCopy], backup_folder + copyNew + "//" + to_backup[copyNew]["fi_s"][filesCopy])
                    shutil.copystat(root_directory + "//" + copyNew + "//" + to_backup[copyNew]["fi_s"][filesCopy], backup_folder + copyNew + "//" + to_backup[copyNew]["fi_s"][filesCopy])
                except Exception as e:
                    errorReport["er_copy_files: "] = root_directory + "//" + copyNew + "//" + to_backup[copyNew]["fi_s"][filesCopy] + " to " + backup_folder + copyNew + "//" + to_backup[copyNew]["fi_s"][filesCopy]
                    errorReport["Error: "] = str(e)
                    errorSave(root_directory, errorReport, backup_folder)
                #print(".", end='', flush=True)  #old version v1.0.0

                #UPDATE FOR FEATURE ENHANCEMENT ON v1.1.0
                #This displays the file that is currently backuped, from the previously used . for each file backuped.
                print("Backup: " + root_directory + "//" + copyNew + "//" + to_backup[copyNew]["fi_s"][filesCopy], flush=True)
    try: 
        os.remove(backup_folder + basename + "//" + ubfileName)
    except Exception as e:
        errorReport["er_remove_oldUBs: "] = backup_folder + basename + "//" + ubfileName
        errorReport["Error: "] = str(e)
        errorSave(root_directory, errorReport, backup_folder)
    try:
        with open(backup_folder + basename + "//" + "UB_" + rand_name + "_" + date + ".UBs", 'w') as ubFiles:
            json.dump(folder_scan, ubFiles)
            ubFiles.close()
    except Exception as e:
        errorReport["er_create_NewUBs: "] = backup_folder + basename + "//" + "UB_" + rand_name + "_" + date + ".UBs"
        errorReport["Error: "] = str(e)
        errorSave(root_directory, errorReport, backup_folder)
    return


def updateBackup(root_directory, backup_folder):
    errorReport = {}
    folder_det = {}
    ubname = str(time.localtime(time.time()).tm_mday) + "." + str(time.localtime(time.time()).tm_mon) + "." + str(time.localtime(time.time()).tm_year)
    rand_name = ''.join(random.choices(string.ascii_letters + string.digits, k=8))
    basefolder = os.path.basename(root_directory)           
    split = root_directory.split("//")                     
    index_basefolder = split.index(basefolder)                 
    elim_sec = '//'.join(split[:index_basefolder]) + '//'
    for folder, subfolder, files in os.walk(root_directory):
        if ("$RECYCLE.BIN" or "found.000" or "System Volume Information") not in folder:
            mod_folder = (folder.replace("\\", "//")).replace(elim_sec, '')
            folder_det[mod_folder] = {}
            try:
                folder_det[mod_folder]["fo_s"], folder_det[mod_folder]["fi_s"], folder_det[mod_folder]["fi_p"] = directoryScan(folder.replace("\\", "//") + "//")
            except Exception as e:
                errorReport["er_directoryScan"] = folder.replace("\\", "//")
                errorReport["Exception: "] = str(e)
                errorSave(root_directory, errorReport, root_directory)
    try: 
        updateEngine(root_directory, backup_folder + "//", folder_det)
    except Exception as e:
        errorReport["er_updateEngine_file"] =root_directory + "//"
        errorReport["Exception: "] = str(e)
        errorSave(root_directory, errorReport, root_directory) 
    return


def updateSimpleBackup(root_directory, backup_folder):
    exception_folder = ["$RECYCLE.BIN", "found.000", "System Volume Information"]
    if root_directory.find("\\")!=-1:
        root_directory = root_directory.replace("\\", "//")
        backup_folder = backup_folder.replace("\\", "//")
    if os.path.isdir(root_directory)==False:
        print("\n   Error, Backup Directory Not found")
        return
    if os.path.isdir(backup_folder)==False:
        print("\n   Error, Folder to backup not found")
        return
    split = root_directory.split("//")
    if len(split)==2 and split[1]=='':  
        list_folders = os.listdir(root_directory)
        for each_root in list_folders:
            if each_root not in exception_folder:
                if os.path.isdir(root_directory + "//" + each_root)==True:
                    updateBackup(root_directory + each_root, backup_folder)
    else:
        updateBackup(root_directory, backup_folder)
    return


if __name__=="__main__":
    print("Checked OK")
    print("This piece of software do not run solo, try import, this is a part of Project Ultra Backup.")